{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6e43fe",
   "metadata": {},
   "source": [
    "# Importing the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a12222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import InputExample\n",
    "from tqdm.auto import tqdm  # so we see progress bar\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "from sentence_transformers import losses\n",
    "import sentence_transformers\n",
    "from transformers import BertTokenizer\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbc1e57",
   "metadata": {},
   "source": [
    "# Loading the dataset into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18d13b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('quora_duplicate_questions.tsv',sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb18f21",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b575b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4525b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95745</th>\n",
       "      <td>95745</td>\n",
       "      <td>159610</td>\n",
       "      <td>159611</td>\n",
       "      <td>How do you say whatever in Spanish?</td>\n",
       "      <td>How do you say 'wildfire' in Spanish?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84108</th>\n",
       "      <td>84108</td>\n",
       "      <td>142248</td>\n",
       "      <td>142249</td>\n",
       "      <td>Can I use satin paint in the feature wall of m...</td>\n",
       "      <td>I want to buy a wall painting as a gift to my ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95744</th>\n",
       "      <td>95744</td>\n",
       "      <td>110572</td>\n",
       "      <td>113370</td>\n",
       "      <td>Why does China support Pakistan a country know...</td>\n",
       "      <td>Why does US, Saudi Arabia and China support Pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282225</th>\n",
       "      <td>282225</td>\n",
       "      <td>17632</td>\n",
       "      <td>49754</td>\n",
       "      <td>What is the reason behind the sudden discontin...</td>\n",
       "      <td>What's the main reason behind 500 &amp; 1000 rs no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402961</th>\n",
       "      <td>402961</td>\n",
       "      <td>536505</td>\n",
       "      <td>536506</td>\n",
       "      <td>How much longer will my cold last?</td>\n",
       "      <td>How long does the average cold virus last?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "95745    95745  159610  159611   \n",
       "84108    84108  142248  142249   \n",
       "95744    95744  110572  113370   \n",
       "282225  282225   17632   49754   \n",
       "402961  402961  536505  536506   \n",
       "\n",
       "                                                question1  \\\n",
       "95745                 How do you say whatever in Spanish?   \n",
       "84108   Can I use satin paint in the feature wall of m...   \n",
       "95744   Why does China support Pakistan a country know...   \n",
       "282225  What is the reason behind the sudden discontin...   \n",
       "402961                 How much longer will my cold last?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "95745               How do you say 'wildfire' in Spanish?             0  \n",
       "84108   I want to buy a wall painting as a gift to my ...             0  \n",
       "95744   Why does US, Saudi Arabia and China support Pa...             0  \n",
       "282225  What's the main reason behind 500 & 1000 rs no...             1  \n",
       "402961         How long does the average cold virus last?             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)    # Viewing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92392b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vs/vqsy9fl90f132y17y_bk2sdm0000gn/T/ipykernel_2072/999382914.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df = df.drop('id',1)    # Dropping the not required id column\n",
      "/var/folders/vs/vqsy9fl90f132y17y_bk2sdm0000gn/T/ipykernel_2072/999382914.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df = df.drop('qid1',1)  # Dropping the not required qid1 column\n",
      "/var/folders/vs/vqsy9fl90f132y17y_bk2sdm0000gn/T/ipykernel_2072/999382914.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df = df.drop('qid2',1)  # Dropping the not required qid2 column\n"
     ]
    }
   ],
   "source": [
    "df = df.drop('id',1)    # Dropping the not required id column\n",
    "df = df.drop('qid1',1)  # Dropping the not required qid1 column\n",
    "df = df.drop('qid2',1)  # Dropping the not required qid2 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a2fb0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape        # Dimension of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b83b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='any',axis=0)    # Dropping rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f21972b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95745</th>\n",
       "      <td>How do you say whatever in Spanish?</td>\n",
       "      <td>How do you say 'wildfire' in Spanish?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84108</th>\n",
       "      <td>Can I use satin paint in the feature wall of m...</td>\n",
       "      <td>I want to buy a wall painting as a gift to my ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95744</th>\n",
       "      <td>Why does China support Pakistan a country know...</td>\n",
       "      <td>Why does US, Saudi Arabia and China support Pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282225</th>\n",
       "      <td>What is the reason behind the sudden discontin...</td>\n",
       "      <td>What's the main reason behind 500 &amp; 1000 rs no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402961</th>\n",
       "      <td>How much longer will my cold last?</td>\n",
       "      <td>How long does the average cold virus last?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "95745                 How do you say whatever in Spanish?   \n",
       "84108   Can I use satin paint in the feature wall of m...   \n",
       "95744   Why does China support Pakistan a country know...   \n",
       "282225  What is the reason behind the sudden discontin...   \n",
       "402961                 How much longer will my cold last?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "95745               How do you say 'wildfire' in Spanish?             0  \n",
       "84108   I want to buy a wall painting as a gift to my ...             0  \n",
       "95744   Why does US, Saudi Arabia and China support Pa...             0  \n",
       "282225  What's the main reason behind 500 & 1000 rs no...             1  \n",
       "402961         How long does the average cold virus last?             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "075c24c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08543cfa",
   "metadata": {},
   "source": [
    "# Splitting the dataframe into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50ec61e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"is_duplicate\"],axis=1)\n",
    "y = df[\"is_duplicate\"]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50baf2c9",
   "metadata": {},
   "source": [
    "# Converting the pandas dataframe into dataset of datasets library using its Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c09b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_train,y_train],axis = 1)\n",
    "test_df = pd.concat([X_test,y_test],axis = 1)\n",
    "train = Dataset.from_pandas(train_df)\n",
    "test = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb85565",
   "metadata": {},
   "source": [
    "# Fine Tuning Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c086d274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640aa3ccf5514e6481242c5e7e973b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Converting the train data columns into an almost matching format with InputExample class\n",
    "train_samples = []\n",
    "for row in tqdm(train):\n",
    "    train_samples.append(InputExample(\n",
    "        texts=[row['question1'], row['question2']],\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bce0927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the data loader\n",
    "from sentence_transformers import datasets\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "loader = datasets.NoDuplicatesDataLoader(\n",
    "    train_samples, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad4f28ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the model by using bert and pooler modules\n",
    "bert = models.Transformer('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "pooler = models.Pooling(\n",
    "    bert.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens=True\n",
    ")\n",
    "\n",
    "model = SentenceTransformer(modules=[bert, pooler])\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc7c08c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to optimize our model that is ready and for that we initialize our loss as MNR loss\n",
    "from sentence_transformers import losses\n",
    "\n",
    "loss = losses.MultipleNegativesRankingLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16754fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nilaypatel/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb410faeb89f4a0098857c65a635bdda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c392da5a3d9485597f2103353bf101e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training our model with the loss and train for single epoch and warm up 10% of the training before\n",
    "epochs = 1\n",
    "warmup_steps = int(len(loader) * epochs * 0.1)\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(loader, loss)],\n",
    "    epochs=epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path='./sbert_test_mnr2',\n",
    "    show_progress_bar=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b9275ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('./sbert_test_mnr2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5189d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f4bbab218e4eefaba7958a4fa6b0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5612f8c158504133835998be3cdf9530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/4.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset glue/stsb (download: 784.05 KiB, generated: 1.09 MiB, post-processed: Unknown size, total: 1.86 MiB) to /Users/nilaypatel/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2902df470d244455911f4d5b0d71c059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/803k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset glue downloaded and prepared to /Users/nilaypatel/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "    num_rows: 1500\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "sts = datasets.load_dataset('glue', 'stsb', split='validation')\n",
    "\n",
    "sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14ab0bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function <lambda> at 0x7f96ddbe5f70> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fd208db4d048e186238c23a0fb3c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sts = sts.map(lambda x: {'label': x['label'] / 5.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94b0ec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for sample in sts:\n",
    "    samples.append(InputExample(\n",
    "        texts=[sample['sentence1'], sample['sentence2']],\n",
    "        label=sample['label']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1b28c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "    samples, write_csv=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05ed54ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8478172504320958"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9730420b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
